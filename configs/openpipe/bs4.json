{
    "model_id": "NousResearch/Meta-Llama-3.1-8B-Instruct",
    "dataset_path": "datasets/zed/large_sample.jsonl",
    "engine_type": "trtllm",
    "engine_kwargs": {
        "build_config":  {
            "plugin_config": {
                "multiple_profiles": true,
                "paged_kv_cache": true,
                "use_paged_context_fmha": true,
                "gemm_plugin": "auto"
            },
            "speculative_decoding_mode": "LOOKAHEAD_DECODING",
            "max_input_len": 4096,
            "max_num_tokens": 65536,
            "max_seq_len": 8192, 
            "max_batch_size": 64
        },
        "speculative_config": {
            "max_window_size" : 8,
            "max_ngram_size" : 6,
            "max_verification_set_size" : 8
        }
    },
    "sampling_kwargs": {
        "temperature": 0.01,
        "max_tokens": 96,
        "skip_special_tokens": true
    },
    "infrastructure_kwargs": {
        "gpu": "H100",
        "max_containers": 1
    },
    "concurrency_kwargs": {
        "max_inputs": 64
    }
}
