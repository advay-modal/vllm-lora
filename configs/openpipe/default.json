{
    "model_id": "NousResearch/Meta-Llama-3.1-8B-Instruct",
    "dataset_path": "datasets/zed/large_sample.jsonl",
    "engine_type": "trtllm",
    "engine_kwargs": {
        "build_config":  {
            "plugin_config": {
                "multiple_profiles": true,
                "paged_kv_cache": true,
                "use_paged_context_fmha": true,
                "gemm_plugin": "auto"
            },
            "lora_config": {
                "lora_dir": ["/loras/summaries-fp16"]
            },
            "max_input_len": 4096,
            "max_num_tokens": 16384,
            "max_seq_len": 16384
        },
        "enable_lora": true,
        "max_lora_rank": 64
    },
    "sampling_kwargs": {
        "temperature": 0.02,
        "max_tokens": 96,
        "skip_special_tokens": true
    }
}

